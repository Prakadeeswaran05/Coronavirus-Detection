{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coronavirus prediction and optimization with tensorrt.ipynb",
      "provenance": [],
      "mount_file_id": "1dJmDuSB0uFZBLvhYbuwxrUO-ZpnWOZUu",
      "authorship_tag": "ABX9TyOZk0KTioPLAvHUKGneFlPV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVjygJ5A9fgB",
        "outputId": "71545f7c-0a69-4a7b-82bd-6825ec3b7006"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 22 13:11:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgkvd1yN9ZU7",
        "outputId": "d837055a-a7a1-4d89-ed52-1a45e2af3d66"
      },
      "source": [
        "%%bash\n",
        "wget -q https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "\n",
        "dpkg -i nvidia-machine-learning-repo-*.deb\n",
        "apt-get -qq update\n",
        "\n",
        "sudo apt-get -qq install libnvinfer5 #libnvinfer6=6.0.1-1+cuda10.1\n",
        "\n",
        "pip install -q tensorflow-gpu==2.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package nvidia-machine-learning-repo-ubuntu1804.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb ...\n",
            "Unpacking nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) ...\n",
            "Setting up nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) ...\n",
            "Selecting previously unselected package libnvinfer5.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 160709 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libnvinfer5_5.1.5-1+cuda10.1_amd64.deb ...\r\n",
            "Unpacking libnvinfer5 (5.1.5-1+cuda10.1) ...\r\n",
            "Setting up libnvinfer5 (5.1.5-1+cuda10.1) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\r\n",
            "\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "ERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\n",
            "ERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 2.0.2 which is incompatible.\n",
            "ERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\n",
            "ERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMRj3Pz-9ejZ",
        "outputId": "98c28f23-8e18-49bb-e8c5-ab4d7c23621f"
      },
      "source": [
        "# check TensorRT version\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \", tf.version.VERSION)\n",
        "print(\"TensorRT version: \")\n",
        "!dpkg -l | grep nvinfer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.0.0\n",
            "TensorRT version: \n",
            "ii  libnvinfer5                             5.1.5-1+cuda10.1                    amd64        TensorRT runtime libraries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBQjDKHW4sMZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "542NWCwo4xin",
        "outputId": "cfab4c51-5e25-4120-ecbb-2eeeda3fe759"
      },
      "source": [
        "vgg19_model= VGG19(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
        "\n",
        "for layer in vgg19_model.layers:\n",
        "  layer.trainable = False\n",
        "vgg19_model.summary()  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T35PDH634z4_",
        "outputId": "e3e55696-b3d4-4606-fd6b-96792849fcc1"
      },
      "source": [
        "x = layers.Flatten()(vgg19_model.output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.3\n",
        "x = layers.Dropout(0.3)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(vgg19_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 45,716,545\n",
            "Trainable params: 25,692,161\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_VSvBPz44IZ",
        "outputId": "80788c98-928a-441e-ff19-868ba6cc5aa9"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_dir='/content/drive/MyDrive/datacov/train'\n",
        "validation_dir='/content/drive/MyDrive/datacov/val'\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (224,224))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (224,224))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2232 images belonging to 2 classes.\n",
            "Found 249 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNfFBMxi47CB",
        "outputId": "861d34b2-9b51-4ad9-b8c2-4629eab0801f"
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            epochs = 35\n",
        "            )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "112/112 [==============================] - 70s 628ms/step - loss: 0.8634 - acc: 0.6165 - val_loss: 0.4625 - val_acc: 0.7751\n",
            "Epoch 2/35\n",
            "112/112 [==============================] - 62s 551ms/step - loss: 0.5455 - acc: 0.7384 - val_loss: 0.3689 - val_acc: 0.8434\n",
            "Epoch 3/35\n",
            "112/112 [==============================] - 62s 550ms/step - loss: 0.5187 - acc: 0.7639 - val_loss: 0.3958 - val_acc: 0.8072\n",
            "Epoch 4/35\n",
            "112/112 [==============================] - 62s 550ms/step - loss: 0.4335 - acc: 0.7944 - val_loss: 0.4181 - val_acc: 0.7831\n",
            "Epoch 5/35\n",
            "112/112 [==============================] - 62s 550ms/step - loss: 0.4394 - acc: 0.8047 - val_loss: 0.2953 - val_acc: 0.8675\n",
            "Epoch 6/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.4181 - acc: 0.8082 - val_loss: 0.3080 - val_acc: 0.8755\n",
            "Epoch 7/35\n",
            "112/112 [==============================] - 62s 550ms/step - loss: 0.3836 - acc: 0.8320 - val_loss: 0.3055 - val_acc: 0.8514\n",
            "Epoch 8/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3934 - acc: 0.8221 - val_loss: 0.4660 - val_acc: 0.7831\n",
            "Epoch 9/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3555 - acc: 0.8472 - val_loss: 0.4968 - val_acc: 0.7631\n",
            "Epoch 10/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3447 - acc: 0.8530 - val_loss: 0.2570 - val_acc: 0.8996\n",
            "Epoch 11/35\n",
            "112/112 [==============================] - 61s 548ms/step - loss: 0.3551 - acc: 0.8463 - val_loss: 0.2511 - val_acc: 0.9157\n",
            "Epoch 12/35\n",
            "112/112 [==============================] - 62s 551ms/step - loss: 0.3158 - acc: 0.8642 - val_loss: 0.2271 - val_acc: 0.9116\n",
            "Epoch 13/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3147 - acc: 0.8634 - val_loss: 0.2563 - val_acc: 0.8956\n",
            "Epoch 14/35\n",
            "112/112 [==============================] - 62s 549ms/step - loss: 0.3254 - acc: 0.8629 - val_loss: 0.2224 - val_acc: 0.9157\n",
            "Epoch 15/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3106 - acc: 0.8781 - val_loss: 0.4159 - val_acc: 0.8032\n",
            "Epoch 16/35\n",
            "112/112 [==============================] - 62s 549ms/step - loss: 0.3149 - acc: 0.8620 - val_loss: 0.2172 - val_acc: 0.9116\n",
            "Epoch 17/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.3003 - acc: 0.8719 - val_loss: 0.2148 - val_acc: 0.9237\n",
            "Epoch 18/35\n",
            "112/112 [==============================] - 62s 550ms/step - loss: 0.2939 - acc: 0.8759 - val_loss: 0.2221 - val_acc: 0.9237\n",
            "Epoch 19/35\n",
            "112/112 [==============================] - 62s 549ms/step - loss: 0.2829 - acc: 0.8795 - val_loss: 0.2482 - val_acc: 0.9116\n",
            "Epoch 20/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2856 - acc: 0.8822 - val_loss: 0.2268 - val_acc: 0.9076\n",
            "Epoch 21/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2853 - acc: 0.8808 - val_loss: 0.2118 - val_acc: 0.9076\n",
            "Epoch 22/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2758 - acc: 0.8840 - val_loss: 0.1886 - val_acc: 0.9277\n",
            "Epoch 23/35\n",
            "112/112 [==============================] - 61s 548ms/step - loss: 0.2688 - acc: 0.8822 - val_loss: 0.2069 - val_acc: 0.9317\n",
            "Epoch 24/35\n",
            "112/112 [==============================] - 61s 548ms/step - loss: 0.2615 - acc: 0.8987 - val_loss: 0.1838 - val_acc: 0.9237\n",
            "Epoch 25/35\n",
            "112/112 [==============================] - 62s 549ms/step - loss: 0.2539 - acc: 0.8965 - val_loss: 0.1987 - val_acc: 0.9357\n",
            "Epoch 26/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2550 - acc: 0.8880 - val_loss: 0.1920 - val_acc: 0.9357\n",
            "Epoch 27/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2511 - acc: 0.8938 - val_loss: 0.1991 - val_acc: 0.9438\n",
            "Epoch 28/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2441 - acc: 0.8902 - val_loss: 0.2252 - val_acc: 0.9277\n",
            "Epoch 29/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2425 - acc: 0.9037 - val_loss: 0.1910 - val_acc: 0.9157\n",
            "Epoch 30/35\n",
            "112/112 [==============================] - 62s 549ms/step - loss: 0.2411 - acc: 0.9001 - val_loss: 0.2111 - val_acc: 0.9197\n",
            "Epoch 31/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2252 - acc: 0.9082 - val_loss: 0.2056 - val_acc: 0.9277\n",
            "Epoch 32/35\n",
            "112/112 [==============================] - 61s 548ms/step - loss: 0.2219 - acc: 0.9185 - val_loss: 0.1779 - val_acc: 0.9398\n",
            "Epoch 33/35\n",
            "112/112 [==============================] - 61s 548ms/step - loss: 0.2293 - acc: 0.9019 - val_loss: 0.1696 - val_acc: 0.9398\n",
            "Epoch 34/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2245 - acc: 0.9050 - val_loss: 0.1869 - val_acc: 0.9197\n",
            "Epoch 35/35\n",
            "112/112 [==============================] - 61s 549ms/step - loss: 0.2117 - acc: 0.9126 - val_loss: 0.1460 - val_acc: 0.9357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3XLJlZgZfC",
        "outputId": "95dbb866-77ed-4b24-8fb5-d87c8627548b"
      },
      "source": [
        "img0 = image.load_img('/content/drive/MyDrive/datacov/val/covid/Covid (1018).png',target_size=(224, 224))\n",
        "x0 = image.img_to_array(img0)\n",
        "x0 = np.expand_dims(x0, axis=0)\n",
        "preds0 = model.predict(x0)\n",
        "print(preds0[0])\n",
        "img1 = image.load_img('/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (101).png',target_size=(224, 224))\n",
        "x1 = image.img_to_array(img1)\n",
        "x1 = np.expand_dims(x1, axis=0)\n",
        "preds1 = model.predict(x1)\n",
        "print(preds1[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.]\n",
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g66FI1Eu5Cxr",
        "outputId": "45ad0c29-42e3-4273-ae47-5ac9b2594b5e"
      },
      "source": [
        "tf.saved_model.save(model,'covid_model')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: covid_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNA0JrKg9YSt",
        "outputId": "50e75ad8-a244-4e2e-915c-c92b5cca5713"
      },
      "source": [
        "!saved_model_cli show --all --dir covid_model/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 224, 224, 3)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_3'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S2T8vFAbqim",
        "outputId": "370e5775-3cfe-46cb-a272-f3e6eb172f93"
      },
      "source": [
        "import os \n",
        "import glob\n",
        "import random\n",
        "img_paths=[]\n",
        "for dir_path in glob.glob('/content/drive/MyDrive/datacov/val/*'):\n",
        "  for file_path in glob.glob(os.path.join(dir_path,\"*.png\")):\n",
        "    img_paths.append(file_path)\n",
        "print(img_paths)\n",
        "length=len(img_paths)\n",
        "shuffled_img_paths=random.sample(img_paths, length)\n",
        "print(shuffled_img_paths)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (8).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (824).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (629).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (810).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (907).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1124).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (799).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (702).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (705).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (285).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (904).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (323).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (140).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (932).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (380).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1205).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (836).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (232).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1175).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (409).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (366).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (87).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (248).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (764).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (528).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1030).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (386).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (548).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (905).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (942).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (569).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (16).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (505).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (162).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1206).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (81).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (36).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (359).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (365).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (173).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (126).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (18).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (275).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (324).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (690).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (6).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1007).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (984).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (302).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (437).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1167).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1002).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1082).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (536).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (262).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (427).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (918).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (78).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1091).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (676).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (46).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (675).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1192).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (444).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1000).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (263).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (156).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (624).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (329).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (652).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (523).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (242).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1179).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1094).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (334).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (645).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (892).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (802).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (42).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (961).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (847).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (688).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (40).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (384).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (630).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (591).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (154).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1050).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (397).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (575).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (492).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1218).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1061).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (867).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1072).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (770).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (529).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (348).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (153).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (667).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (913).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (50).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (99).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (925).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (142).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1014).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (570).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (448).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (742).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (278).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (481).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (823).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (311).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1153).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (349).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (931).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (972).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (406).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (333).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1226).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (619).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (101).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (169).png', '/content/drive/MyDrive/datacov/val/covid/Covid (267).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1028).png', '/content/drive/MyDrive/datacov/val/covid/Covid (280).png', '/content/drive/MyDrive/datacov/val/covid/Covid (486).png', '/content/drive/MyDrive/datacov/val/covid/Covid (865).png', '/content/drive/MyDrive/datacov/val/covid/Covid (742).png', '/content/drive/MyDrive/datacov/val/covid/Covid (244).png', '/content/drive/MyDrive/datacov/val/covid/Covid (290).png', '/content/drive/MyDrive/datacov/val/covid/Covid (183).png', '/content/drive/MyDrive/datacov/val/covid/Covid (503).png', '/content/drive/MyDrive/datacov/val/covid/Covid (87).png', '/content/drive/MyDrive/datacov/val/covid/Covid (792).png', '/content/drive/MyDrive/datacov/val/covid/Covid (132).png', '/content/drive/MyDrive/datacov/val/covid/Covid (221).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1055).png', '/content/drive/MyDrive/datacov/val/covid/Covid (497).png', '/content/drive/MyDrive/datacov/val/covid/Covid (640).png', '/content/drive/MyDrive/datacov/val/covid/Covid (139).png', '/content/drive/MyDrive/datacov/val/covid/Covid (567).png', '/content/drive/MyDrive/datacov/val/covid/Covid (176).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1027).png', '/content/drive/MyDrive/datacov/val/covid/Covid (874).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1018).png', '/content/drive/MyDrive/datacov/val/covid/Covid (607).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1186).png', '/content/drive/MyDrive/datacov/val/covid/Covid (679).png', '/content/drive/MyDrive/datacov/val/covid/Covid (620).png', '/content/drive/MyDrive/datacov/val/covid/Covid (819).png', '/content/drive/MyDrive/datacov/val/covid/Covid (600).png', '/content/drive/MyDrive/datacov/val/covid/Covid (74).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1170).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1171).png', '/content/drive/MyDrive/datacov/val/covid/Covid (122).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1085).png', '/content/drive/MyDrive/datacov/val/covid/Covid (535).png', '/content/drive/MyDrive/datacov/val/covid/Covid (356).png', '/content/drive/MyDrive/datacov/val/covid/Covid (572).png', '/content/drive/MyDrive/datacov/val/covid/Covid (212).png', '/content/drive/MyDrive/datacov/val/covid/Covid (746).png', '/content/drive/MyDrive/datacov/val/covid/Covid (171).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1114).png', '/content/drive/MyDrive/datacov/val/covid/Covid (633).png', '/content/drive/MyDrive/datacov/val/covid/Covid (432).png', '/content/drive/MyDrive/datacov/val/covid/Covid (270).png', '/content/drive/MyDrive/datacov/val/covid/Covid (892).png', '/content/drive/MyDrive/datacov/val/covid/Covid (359).png', '/content/drive/MyDrive/datacov/val/covid/Covid (223).png', '/content/drive/MyDrive/datacov/val/covid/Covid (466).png', '/content/drive/MyDrive/datacov/val/covid/Covid (752).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1141).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1099).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1139).png', '/content/drive/MyDrive/datacov/val/covid/Covid (824).png', '/content/drive/MyDrive/datacov/val/covid/Covid (220).png', '/content/drive/MyDrive/datacov/val/covid/Covid (225).png', '/content/drive/MyDrive/datacov/val/covid/Covid (467).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1176).png', '/content/drive/MyDrive/datacov/val/covid/Covid (33).png', '/content/drive/MyDrive/datacov/val/covid/Covid (652).png', '/content/drive/MyDrive/datacov/val/covid/Covid (35).png', '/content/drive/MyDrive/datacov/val/covid/Covid (315).png', '/content/drive/MyDrive/datacov/val/covid/Covid (785).png', '/content/drive/MyDrive/datacov/val/covid/Covid (933).png', '/content/drive/MyDrive/datacov/val/covid/Covid (281).png', '/content/drive/MyDrive/datacov/val/covid/Covid (360).png', '/content/drive/MyDrive/datacov/val/covid/Covid (13).png', '/content/drive/MyDrive/datacov/val/covid/Covid (291).png', '/content/drive/MyDrive/datacov/val/covid/Covid (510).png', '/content/drive/MyDrive/datacov/val/covid/Covid (118).png', '/content/drive/MyDrive/datacov/val/covid/Covid (724).png', '/content/drive/MyDrive/datacov/val/covid/Covid (977).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1015).png', '/content/drive/MyDrive/datacov/val/covid/Covid (214).png', '/content/drive/MyDrive/datacov/val/covid/Covid (53).png', '/content/drive/MyDrive/datacov/val/covid/Covid (712).png', '/content/drive/MyDrive/datacov/val/covid/Covid (809).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1138).png', '/content/drive/MyDrive/datacov/val/covid/Covid (844).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1178).png', '/content/drive/MyDrive/datacov/val/covid/Covid (920).png', '/content/drive/MyDrive/datacov/val/covid/Covid (598).png', '/content/drive/MyDrive/datacov/val/covid/Covid (756).png', '/content/drive/MyDrive/datacov/val/covid/Covid (835).png', '/content/drive/MyDrive/datacov/val/covid/Covid (898).png', '/content/drive/MyDrive/datacov/val/covid/Covid (901).png', '/content/drive/MyDrive/datacov/val/covid/Covid (422).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1247).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1188).png', '/content/drive/MyDrive/datacov/val/covid/Covid (202).png', '/content/drive/MyDrive/datacov/val/covid/Covid (967).png', '/content/drive/MyDrive/datacov/val/covid/Covid (341).png', '/content/drive/MyDrive/datacov/val/covid/Covid (73).png', '/content/drive/MyDrive/datacov/val/covid/Covid (358).png', '/content/drive/MyDrive/datacov/val/covid/Covid (216).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1251).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1033).png', '/content/drive/MyDrive/datacov/val/covid/Covid (36).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1172).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1210).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1190).png', '/content/drive/MyDrive/datacov/val/covid/Covid (867).png', '/content/drive/MyDrive/datacov/val/covid/Covid (347).png', '/content/drive/MyDrive/datacov/val/covid/Covid (581).png', '/content/drive/MyDrive/datacov/val/covid/Covid (661).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1112).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1205).png', '/content/drive/MyDrive/datacov/val/covid/Covid (968).png', '/content/drive/MyDrive/datacov/val/covid/Covid (437).png', '/content/drive/MyDrive/datacov/val/covid/Covid (167).png', '/content/drive/MyDrive/datacov/val/covid/Covid (282).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1058).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1010).png', '/content/drive/MyDrive/datacov/val/covid/Covid (606).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1234).png', '/content/drive/MyDrive/datacov/val/covid/Covid (489).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1145).png', '/content/drive/MyDrive/datacov/val/covid/Covid (634).png', '/content/drive/MyDrive/datacov/val/covid/Covid (47).png', '/content/drive/MyDrive/datacov/val/covid/Covid (948).png', '/content/drive/MyDrive/datacov/val/covid/Covid (352).png', '/content/drive/MyDrive/datacov/val/covid/Covid (130).png', '/content/drive/MyDrive/datacov/val/covid/Covid (839).png', '/content/drive/MyDrive/datacov/val/covid/Covid (324).png', '/content/drive/MyDrive/datacov/val/covid/Covid (248).png', '/content/drive/MyDrive/datacov/val/covid/Covid (141).png', '/content/drive/MyDrive/datacov/val/covid/Covid (261).png']\n",
            "['/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (536).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (348).png', '/content/drive/MyDrive/datacov/val/covid/Covid (535).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (232).png', '/content/drive/MyDrive/datacov/val/covid/Covid (712).png', '/content/drive/MyDrive/datacov/val/covid/Covid (225).png', '/content/drive/MyDrive/datacov/val/covid/Covid (220).png', '/content/drive/MyDrive/datacov/val/covid/Covid (510).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1192).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (529).png', '/content/drive/MyDrive/datacov/val/covid/Covid (214).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (285).png', '/content/drive/MyDrive/datacov/val/covid/Covid (898).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1085).png', '/content/drive/MyDrive/datacov/val/covid/Covid (267).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1153).png', '/content/drive/MyDrive/datacov/val/covid/Covid (36).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (705).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (6).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1186).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (87).png', '/content/drive/MyDrive/datacov/val/covid/Covid (933).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (802).png', '/content/drive/MyDrive/datacov/val/covid/Covid (202).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1139).png', '/content/drive/MyDrive/datacov/val/covid/Covid (422).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1206).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (688).png', '/content/drive/MyDrive/datacov/val/covid/Covid (341).png', '/content/drive/MyDrive/datacov/val/covid/Covid (467).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (570).png', '/content/drive/MyDrive/datacov/val/covid/Covid (356).png', '/content/drive/MyDrive/datacov/val/covid/Covid (486).png', '/content/drive/MyDrive/datacov/val/covid/Covid (216).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1082).png', '/content/drive/MyDrive/datacov/val/covid/Covid (920).png', '/content/drive/MyDrive/datacov/val/covid/Covid (291).png', '/content/drive/MyDrive/datacov/val/covid/Covid (33).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (569).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1167).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1141).png', '/content/drive/MyDrive/datacov/val/covid/Covid (282).png', '/content/drive/MyDrive/datacov/val/covid/Covid (967).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (645).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1175).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (836).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (153).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (242).png', '/content/drive/MyDrive/datacov/val/covid/Covid (581).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (961).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1205).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1099).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (386).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (931).png', '/content/drive/MyDrive/datacov/val/covid/Covid (73).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (591).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (409).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (334).png', '/content/drive/MyDrive/datacov/val/covid/Covid (835).png', '/content/drive/MyDrive/datacov/val/covid/Covid (633).png', '/content/drive/MyDrive/datacov/val/covid/Covid (139).png', '/content/drive/MyDrive/datacov/val/covid/Covid (359).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1178).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (349).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1002).png', '/content/drive/MyDrive/datacov/val/covid/Covid (752).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1172).png', '/content/drive/MyDrive/datacov/val/covid/Covid (497).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (823).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1124).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1094).png', '/content/drive/MyDrive/datacov/val/covid/Covid (432).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (824).png', '/content/drive/MyDrive/datacov/val/covid/Covid (503).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1138).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1171).png', '/content/drive/MyDrive/datacov/val/covid/Covid (281).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1218).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (984).png', '/content/drive/MyDrive/datacov/val/covid/Covid (865).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1033).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (50).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (629).png', '/content/drive/MyDrive/datacov/val/covid/Covid (53).png', '/content/drive/MyDrive/datacov/val/covid/Covid (130).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (384).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (36).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (397).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (770).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1018).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (437).png', '/content/drive/MyDrive/datacov/val/covid/Covid (607).png', '/content/drive/MyDrive/datacov/val/covid/Covid (724).png', '/content/drive/MyDrive/datacov/val/covid/Covid (598).png', '/content/drive/MyDrive/datacov/val/covid/Covid (640).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (142).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (18).png', '/content/drive/MyDrive/datacov/val/covid/Covid (358).png', '/content/drive/MyDrive/datacov/val/covid/Covid (567).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (528).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (667).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (492).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (302).png', '/content/drive/MyDrive/datacov/val/covid/Covid (167).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1058).png', '/content/drive/MyDrive/datacov/val/covid/Covid (347).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (169).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (972).png', '/content/drive/MyDrive/datacov/val/covid/Covid (600).png', '/content/drive/MyDrive/datacov/val/covid/Covid (652).png', '/content/drive/MyDrive/datacov/val/covid/Covid (606).png', '/content/drive/MyDrive/datacov/val/covid/Covid (437).png', '/content/drive/MyDrive/datacov/val/covid/Covid (183).png', '/content/drive/MyDrive/datacov/val/covid/Covid (620).png', '/content/drive/MyDrive/datacov/val/covid/Covid (13).png', '/content/drive/MyDrive/datacov/val/covid/Covid (819).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1007).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (575).png', '/content/drive/MyDrive/datacov/val/covid/Covid (809).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (942).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (81).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (847).png', '/content/drive/MyDrive/datacov/val/covid/Covid (746).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (427).png', '/content/drive/MyDrive/datacov/val/covid/Covid (244).png', '/content/drive/MyDrive/datacov/val/covid/Covid (792).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1015).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (380).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1030).png', '/content/drive/MyDrive/datacov/val/covid/Covid (261).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1234).png', '/content/drive/MyDrive/datacov/val/covid/Covid (87).png', '/content/drive/MyDrive/datacov/val/covid/Covid (270).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1050).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (932).png', '/content/drive/MyDrive/datacov/val/covid/Covid (844).png', '/content/drive/MyDrive/datacov/val/covid/Covid (756).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (359).png', '/content/drive/MyDrive/datacov/val/covid/Covid (824).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1027).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1000).png', '/content/drive/MyDrive/datacov/val/covid/Covid (892).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (905).png', '/content/drive/MyDrive/datacov/val/covid/Covid (661).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (505).png', '/content/drive/MyDrive/datacov/val/covid/Covid (223).png', '/content/drive/MyDrive/datacov/val/covid/Covid (360).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (278).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (8).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (444).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (690).png', '/content/drive/MyDrive/datacov/val/covid/Covid (122).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (799).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (481).png', '/content/drive/MyDrive/datacov/val/covid/Covid (901).png', '/content/drive/MyDrive/datacov/val/covid/Covid (489).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (406).png', '/content/drive/MyDrive/datacov/val/covid/Covid (634).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (652).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (913).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1072).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (16).png', '/content/drive/MyDrive/datacov/val/covid/Covid (248).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (46).png', '/content/drive/MyDrive/datacov/val/covid/Covid (315).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (275).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (742).png', '/content/drive/MyDrive/datacov/val/covid/Covid (466).png', '/content/drive/MyDrive/datacov/val/covid/Covid (977).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (548).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1061).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (78).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (810).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1028).png', '/content/drive/MyDrive/datacov/val/covid/Covid (176).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (918).png', '/content/drive/MyDrive/datacov/val/covid/Covid (118).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (892).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (42).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (323).png', '/content/drive/MyDrive/datacov/val/covid/Covid (35).png', '/content/drive/MyDrive/datacov/val/covid/Covid (47).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (40).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (675).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (619).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1188).png', '/content/drive/MyDrive/datacov/val/covid/Covid (968).png', '/content/drive/MyDrive/datacov/val/covid/Covid (679).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (248).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1205).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1055).png', '/content/drive/MyDrive/datacov/val/covid/Covid (874).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1145).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (154).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (702).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (366).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (907).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1247).png', '/content/drive/MyDrive/datacov/val/covid/Covid (280).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1179).png', '/content/drive/MyDrive/datacov/val/covid/Covid (948).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (329).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1176).png', '/content/drive/MyDrive/datacov/val/covid/Covid (212).png', '/content/drive/MyDrive/datacov/val/covid/Covid (324).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1114).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (925).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (263).png', '/content/drive/MyDrive/datacov/val/covid/Covid (352).png', '/content/drive/MyDrive/datacov/val/covid/Covid (171).png', '/content/drive/MyDrive/datacov/val/covid/Covid (141).png', '/content/drive/MyDrive/datacov/val/covid/Covid (867).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (101).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (262).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (333).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (904).png', '/content/drive/MyDrive/datacov/val/covid/Covid (74).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (162).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (630).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (764).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1190).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1251).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (324).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1014).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (867).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1226).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (156).png', '/content/drive/MyDrive/datacov/val/covid/Covid (132).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (448).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (1091).png', '/content/drive/MyDrive/datacov/val/covid/Covid (572).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (676).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (523).png', '/content/drive/MyDrive/datacov/val/covid/Covid (290).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (624).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (311).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (99).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (126).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1112).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (140).png', '/content/drive/MyDrive/datacov/val/covid/Covid (785).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (173).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1210).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1170).png', '/content/drive/MyDrive/datacov/val/covid/Covid (742).png', '/content/drive/MyDrive/datacov/val/covid/Covid (221).png', '/content/drive/MyDrive/datacov/val/covid/Covid (1010).png', '/content/drive/MyDrive/datacov/val/covid/Covid (839).png', '/content/drive/MyDrive/datacov/val/no_covid/Non-Covid (365).png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD0lpi93aDHU"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "def batch_input(batch_size=8):\n",
        "  batched_input=np.zeros((batch_size,224,224,3),dtype=np.float32)\n",
        "  for i in range(batch_size):\n",
        "    img_path=shuffled_img_paths[i]\n",
        "    img=image.load_img(img_path,target_size=(224,224))\n",
        "    x=image.img_to_array(img)\n",
        "    x=np.expand_dims(x,axis=0)\n",
        "    batched_input[i,:]=x\n",
        "\n",
        "    batched_input=tf.constant(batched_input) #convert to tf eagertensor\n",
        "    return batched_input\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KqmgNzycpLA",
        "outputId": "b95742f7-20d4-41ef-cfb1-13334461d11e"
      },
      "source": [
        "batched_input=batch_input(batch_size=32)\n",
        "batched_input.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 224, 224, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ4-lAVRfmoB"
      },
      "source": [
        "from tensorflow.python.saved_model import tag_constants\n",
        "def load_tf_saved_model(input_saved_model_dir):\n",
        "  print(f'Loading saved model{input_saved_model_dir}....')\n",
        "  saved_model_loaded=tf.saved_model.load(input_saved_model_dir,tags=[tag_constants.SERVING])\n",
        "  return saved_model_loaded"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuzcbmIzfzpZ",
        "outputId": "068f3a15-d9b1-4695-fa95-f5a230350884"
      },
      "source": [
        "saved_model=load_tf_saved_model('covid_model')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading saved modelcovid_model....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNmY_oT9f_jn",
        "outputId": "ecee122f-a2fe-4228-d87d-e93e5f7153d0"
      },
      "source": [
        "infer=saved_model.signatures['serving_default']\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dense_3': TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_3')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To_3kPs0hiG5"
      },
      "source": [
        "import time\n",
        "def predict_and_benchmark_throughput(batched_input, infer, N_warmup_run=50, N_run=1000):\n",
        "\n",
        "  elapsed_time = []\n",
        "  all_preds = []\n",
        "  batch_size = batched_input.shape[0]\n",
        "\n",
        "  for i in range(N_warmup_run):\n",
        "    labeling = infer(batched_input)\n",
        "    preds = labeling['dense_3'].numpy()\n",
        "\n",
        "  for i in range(N_run):\n",
        "    start_time = time.time()\n",
        "\n",
        "    labeling = infer(batched_input)\n",
        "\n",
        "    preds = labeling['dense_3'].numpy()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
        "    \n",
        "    all_preds.append(preds)\n",
        "\n",
        "    if i % 50 == 0:\n",
        "      print('Steps {}-{} average: {:4.1f}ms'.format(i, i+50, (elapsed_time[-50:].mean()) * 1000))\n",
        "\n",
        "  print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))\n",
        "  return all_preds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhw2k793hqiG",
        "outputId": "41cc20f2-08d9-456b-b161-ca98279e6dd7"
      },
      "source": [
        "# without tensorrt optimized model predcition speed\n",
        "all_preds=predict_and_benchmark_throughput(batched_input,infer,N_warmup_run=50,N_run=1000)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps 0-50 average: 159.7ms\n",
            "Steps 50-100 average: 160.6ms\n",
            "Steps 100-150 average: 162.4ms\n",
            "Steps 150-200 average: 162.5ms\n",
            "Steps 200-250 average: 161.0ms\n",
            "Steps 250-300 average: 159.4ms\n",
            "Steps 300-350 average: 158.5ms\n",
            "Steps 350-400 average: 158.1ms\n",
            "Steps 400-450 average: 157.8ms\n",
            "Steps 450-500 average: 158.0ms\n",
            "Steps 500-550 average: 158.5ms\n",
            "Steps 550-600 average: 159.4ms\n",
            "Steps 600-650 average: 159.8ms\n",
            "Steps 650-700 average: 160.0ms\n",
            "Steps 700-750 average: 159.9ms\n",
            "Steps 750-800 average: 159.7ms\n",
            "Steps 800-850 average: 159.4ms\n",
            "Steps 850-900 average: 159.1ms\n",
            "Steps 900-950 average: 158.8ms\n",
            "Steps 950-1000 average: 158.9ms\n",
            "Throughput: 201 images/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYjyCrGEjaok",
        "outputId": "d08f112e-7836-4a61-e638-18fc9e9ed31f"
      },
      "source": [
        "#Testing without tensorrt optimized model with the same image\n",
        "test_im = image.load_img('/content/drive/MyDrive/datacov/val/covid/Covid (1018).png',target_size=(224, 224))\n",
        "x_test1= image.img_to_array(test_im)\n",
        "x_test1= np.expand_dims(x_test1, axis=0)\n",
        "x_test1=tf.constant(x_test1)\n",
        "labeling = infer(x_test1)\n",
        "preds = labeling['dense_3'].numpy()\n",
        "print(preds)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4TKBTt4ZQY3"
      },
      "source": [
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "def convert_to_trt_graph_and_save(precision_mode='float16',input_saved_model_dir='covid_model',calibration_data=batched_input):\n",
        "  if precision_mode=='float16':\n",
        "    precision_mode=trt.TrtPrecisionMode.FP16\n",
        "    converted_save_suffix='_TFTRT_FP16'\n",
        "  output_saved_model_dir=input_saved_model_dir+converted_save_suffix\n",
        "  conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
        "  precision_mode=precision_mode,\n",
        "  max_workspace_size_bytes=8000000000)\n",
        "  converter=trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir,conversion_params=conversion_params)\n",
        "\n",
        "  print(f'Converting {input_saved_model_dir} to TF-TRT graph precision mode {precision_mode} ....')\n",
        "  converter.convert()\n",
        "  print(f'Saving converted model to {output_saved_model_dir}')\n",
        "  converter.save(output_saved_model_dir=output_saved_model_dir)\n",
        "  print('complete')\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyacEIbqfy8e",
        "outputId": "ff1a84bd-039d-4f4e-a685-ce305162f67a"
      },
      "source": [
        "convert_to_trt_graph_and_save(precision_mode='float16',input_saved_model_dir='covid_model')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Linked TensorRT version: (5, 1, 5)\n",
            "INFO:tensorflow:Loaded TensorRT version: (5, 1, 5)\n",
            "INFO:tensorflow:Running against TensorRT version 5.1.5\n",
            "Converting covid_model to TF-TRT graph precision mode FP16 ....\n",
            "Saving converted model to covid_model_TFTRT_FP16\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: covid_model_TFTRT_FP16/assets\n",
            "complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZgDVlHQZ8Wh",
        "outputId": "1e5cbb78-2577-4bb8-cf84-a3480b8dee01"
      },
      "source": [
        "saved_model_trt=load_tf_saved_model('/content/covid_model_TFTRT_FP16')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading saved model/content/covid_model_TFTRT_FP16....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2DoRznslS8g"
      },
      "source": [
        "infer_trt=saved_model_trt.signatures['serving_default']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ7lrlOdlXn-",
        "outputId": "810be403-bf2a-4c36-a85f-531d3e4378e4"
      },
      "source": [
        "#tensorrt optimized model predcition speed\n",
        "all_preds_trt=predict_and_benchmark_throughput(batched_input,infer_trt,N_warmup_run=50,N_run=1000)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps 0-50 average: 59.9ms\n",
            "Steps 50-100 average: 59.3ms\n",
            "Steps 100-150 average: 59.5ms\n",
            "Steps 150-200 average: 59.9ms\n",
            "Steps 200-250 average: 60.9ms\n",
            "Steps 250-300 average: 60.9ms\n",
            "Steps 300-350 average: 60.9ms\n",
            "Steps 350-400 average: 60.9ms\n",
            "Steps 400-450 average: 60.8ms\n",
            "Steps 450-500 average: 60.8ms\n",
            "Steps 500-550 average: 60.9ms\n",
            "Steps 550-600 average: 60.4ms\n",
            "Steps 600-650 average: 60.1ms\n",
            "Steps 650-700 average: 59.5ms\n",
            "Steps 700-750 average: 59.3ms\n",
            "Steps 750-800 average: 58.9ms\n",
            "Steps 800-850 average: 59.0ms\n",
            "Steps 850-900 average: 58.7ms\n",
            "Steps 900-950 average: 58.5ms\n",
            "Steps 950-1000 average: 58.5ms\n",
            "Throughput: 535 images/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSufX-5lgNh",
        "outputId": "7b740e07-de5a-4acc-ab14-12102ba5c567"
      },
      "source": [
        "#Testing on tensorrt fp16 optimized model with the same image\n",
        "test_im_trt = image.load_img('/content/drive/MyDrive/datacov/val/covid/Covid (1018).png',target_size=(224, 224))\n",
        "x_test1_trt= image.img_to_array(test_im_trt)\n",
        "x_test1_trt= np.expand_dims(x_test1_trt, axis=0)\n",
        "x_test1_trt=tf.constant(x_test1_trt)\n",
        "labeling_trt = infer_trt(x_test1_trt)\n",
        "preds_trt = labeling_trt['dense_3'].numpy()\n",
        "print(preds_trt)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEGoXPJJn3ng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}